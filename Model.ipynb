{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1582 files belonging to 3 classes.\n",
      "Using 1266 files for training.\n",
      "Found 1582 files belonging to 3 classes.\n",
      "Using 316 files for validation.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 14:56:46.721680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.7597 - accuracy: 0.7022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 14:56:50.127462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 78ms/step - loss: 0.7597 - accuracy: 0.7022 - val_loss: 0.5175 - val_accuracy: 0.7943\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.4224 - accuracy: 0.8341 - val_loss: 0.3903 - val_accuracy: 0.8608\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.2920 - accuracy: 0.8918 - val_loss: 0.3716 - val_accuracy: 0.8576\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.2338 - accuracy: 0.9084 - val_loss: 0.3516 - val_accuracy: 0.8576\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1813 - accuracy: 0.9352 - val_loss: 0.3484 - val_accuracy: 0.8861\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.2557 - accuracy: 0.8997 - val_loss: 0.4861 - val_accuracy: 0.8228\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.1443 - accuracy: 0.9494 - val_loss: 0.3727 - val_accuracy: 0.8829\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.0610 - accuracy: 0.9826 - val_loss: 0.4247 - val_accuracy: 0.8797\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0325 - accuracy: 0.9929 - val_loss: 0.4644 - val_accuracy: 0.8671\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.4411 - val_accuracy: 0.8639\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.5599 - val_accuracy: 0.8291\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.5577 - val_accuracy: 0.8703\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.6588 - val_accuracy: 0.8481\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5589 - val_accuracy: 0.8924\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5558 - val_accuracy: 0.8797\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 5.6691e-04 - accuracy: 1.0000 - val_loss: 0.5958 - val_accuracy: 0.8829\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 4.1114e-04 - accuracy: 1.0000 - val_loss: 0.6144 - val_accuracy: 0.8956\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 3.3657e-04 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.8861\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 2.8426e-04 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8924\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 2.3517e-04 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.8892\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "#processing images\n",
    "healthy_path = '/Users/granthough/Documents/GitHub/Corally/Dataset/Healthy/*.png'\n",
    "bleached_path = '/Users/granthough/Documents/GitHub/Corally/Dataset/Bleached/*.png'\n",
    "dead_path = '/Users/granthough/Documents/GitHub/Corally/Dataset/Dead/*.png'\n",
    "\n",
    "#all images are 227x227 in RGB so 227, 227, 3\n",
    "healthy_images = [cv2.imread(image) for image in glob.glob(healthy_path)]\n",
    "bleached_images = [cv2.imread(image) for image in glob.glob(bleached_path)]\n",
    "dead_images = [cv2.imread(image) for image in glob.glob(dead_path)]\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/Users/granthough/Documents/Github/Corally/Dataset',\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 24,  \n",
    "    image_size = (227, 227),\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/Users/granthough/Documents/Github/Corally/Dataset',\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 24,  \n",
    "    image_size = (227, 227),\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.cache().shuffle(13).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().shuffle(13).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "\n",
    "model = Sequential ([\n",
    "    layers.Rescaling(1./255, input_shape = (227, 227, 3)),\n",
    "    layers.Conv2D(16, 3, padding = 'same', activation = 'relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])\n",
    "\n",
    "model.fit (\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    epochs = 20\n",
    ")\n",
    "model.save('model.h5')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed62fe37c70c43daf53734f0e82fe51afbd842bd3927931b3d8d095f4b2d0af7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
