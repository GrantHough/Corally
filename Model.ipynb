{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1582 files belonging to 3 classes.\n",
      "Using 1266 files for training.\n",
      "Found 1582 files belonging to 3 classes.\n",
      "Using 316 files for validation.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 17:08:24.897891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.7941 - accuracy: 0.6840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 17:08:28.486023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 86ms/step - loss: 0.7941 - accuracy: 0.6840 - val_loss: 0.5140 - val_accuracy: 0.8101\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.4869 - accuracy: 0.8096 - val_loss: 0.3820 - val_accuracy: 0.8734\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.3547 - accuracy: 0.8633 - val_loss: 0.3515 - val_accuracy: 0.8766\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.2665 - accuracy: 0.8989 - val_loss: 0.3600 - val_accuracy: 0.8418\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1925 - accuracy: 0.9265 - val_loss: 0.4754 - val_accuracy: 0.8133\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1470 - accuracy: 0.9487 - val_loss: 0.3867 - val_accuracy: 0.8987\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1292 - accuracy: 0.9479 - val_loss: 0.4518 - val_accuracy: 0.8291\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0697 - accuracy: 0.9771 - val_loss: 0.4983 - val_accuracy: 0.8323\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.1080 - accuracy: 0.9613 - val_loss: 0.3418 - val_accuracy: 0.8734\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.0615 - accuracy: 0.9803 - val_loss: 0.4659 - val_accuracy: 0.8165\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0324 - accuracy: 0.9937 - val_loss: 0.3634 - val_accuracy: 0.9019\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.4352 - val_accuracy: 0.8829\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.8924\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.8956\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 9.5082e-04 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.8861\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 8.4573e-04 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.8797\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 5.6829e-04 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.8829\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 2s 63ms/step - loss: 4.3747e-04 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.8797\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 3.7856e-04 - accuracy: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.8797\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 3.0727e-04 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.8797\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "#processing images\n",
    "healthy_path = '/Users/granthough/Documents/GitHub/Corally/Dataset/Healthy/*.png'\n",
    "bleached_path = '/Users/granthough/Documents/GitHub/Corally/Dataset/Bleached/*.png'\n",
    "dead_path = '/Users/granthough/Documents/GitHub/Corally/Dataset/Dead/*.png'\n",
    "\n",
    "#all images are 227x227 in RGB so 227, 227, 3\n",
    "healthy_images = [cv2.imread(image) for image in glob.glob(healthy_path)]\n",
    "bleached_images = [cv2.imread(image) for image in glob.glob(bleached_path)]\n",
    "dead_images = [cv2.imread(image) for image in glob.glob(dead_path)]\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/Users/granthough/Documents/Github/Corally/Dataset',\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 24,  \n",
    "    image_size = (227, 227),\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/Users/granthough/Documents/Github/Corally/Dataset',\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 24,  \n",
    "    image_size = (227, 227),\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.cache().shuffle(13).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().shuffle(13).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "\n",
    "model = Sequential ([\n",
    "    layers.Rescaling(1./255, input_shape = (227, 227, 3)),\n",
    "    layers.Conv2D(16, 3, padding = 'same', activation = 'relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])\n",
    "\n",
    "model.fit (\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    epochs = 20\n",
    ")\n",
    "model.save('model.h5')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed62fe37c70c43daf53734f0e82fe51afbd842bd3927931b3d8d095f4b2d0af7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
